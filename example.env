# LLM Configuration
# Choose your LLM model - supports OpenAI, Anthropic, local models, and more
LLM_MODEL="gpt-3.5-turbo"
# LLM_MODEL="gpt-4"
# LLM_MODEL="claude-3-sonnet-20240229"
# LLM_MODEL="ollama/llama2"
# LLM_MODEL="ollama/mistral"

# Enable debug logging for LLM calls
LLM_DEBUG="false"

# API Keys for different providers (only set the ones you're using)
# OpenAI API Key (for gpt models)
OPENAI_API_KEY="your_openai_api_key_here"

# Anthropic API Key (for claude models)
ANTHROPIC_API_KEY="your_anthropic_api_key_here"

# Ollama Configuration (for local models)
# OLLAMA_BASE_URL="http://localhost:11434"

# Other LLM Provider Keys (as needed)
# COHERE_API_KEY="your_cohere_api_key_here"
# HUGGINGFACE_API_KEY="your_hf_api_key_here"